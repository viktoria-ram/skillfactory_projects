{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notebook info\n",
    "\n",
    "In this notebook you will find a code to parse the data from auto.ru website.\n",
    "As parsing takes a lot of time i decided to parse only the car brands we have in the test data set in kaggle. \n",
    "Test dataset consists about 30K rows. That means we need at least 60K rows in the train dataset to have a 70/30 train/tst split.\n",
    "\n",
    "The notebook is splitted into two parts:\n",
    "- 1. create a list of URL' we will parse\n",
    "- 2. loop which go through all the URL's from the first part and collect the information into one dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4.dammit import EncodingDetector\n",
    "import requests\n",
    "import pandas as pd\n",
    "from progressbar import ProgressBar\n",
    "pbar = ProgressBar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define brands\n",
    "brands_from_kaggle_dataset = ['skoda', 'audi', 'honda', 'volvo', 'bmw', 'nissan', 'infiniti',\n",
    "       'mercedes', 'toyota', 'lexus', 'volkswagen', 'mitsubishi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. create list of URL's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create emty list\n",
    "urls_list_for_parsing_ = []\n",
    "\n",
    "\n",
    "for brand in pbar(brands_from_kaggle_dataset):\n",
    "    for i in range(0, 150):     # number of pages for parsing\n",
    "        parser = 'html.parser'\n",
    "        resp = requests.get(\n",
    "            f'https://auto.ru/moskva/cars/{brand}/used/?output_type=list&page={i}')\n",
    "        http_encoding = resp.encoding if 'charset' in resp.headers.get(\n",
    "            'content-type', '').lower() else None\n",
    "        html_encoding = EncodingDetector.find_declared_encoding(\n",
    "            resp.content, is_html=True)\n",
    "        encoding = html_encoding or http_encoding\n",
    "        soup = BeautifulSoup(resp.content, parser, from_encoding=encoding)\n",
    "\n",
    "        for link in soup.find_all('a', class_='Link ListingItemTitle-module__link', href=True):\n",
    "            urls_list_for_parsing_.append(link['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. create a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['brand', 'model_name', 'price', 'год выпуска', 'Пробег', 'Кузов', 'Цвет', 'Двигатель', 'Налог',\n",
    "                'Коробка', 'Привод', 'Руль', 'Состояние', 'Владельцы', 'ПТС', 'Таможня', 'VIN', 'Госномер', 'comment']\n",
    "\n",
    "df = pd.DataFrame(columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in pbar(urls_part2):\n",
    "    try:\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        response.encoding = 'utf-8'\n",
    "        page = BeautifulSoup(response.text, 'html.parser')\n",
    "        # create empty list with auto characteristics\n",
    "        auto_characteristics = []\n",
    "        # add body type\n",
    "        auto_characteristics.append('brand')\n",
    "        auto_characteristics.append(url.split('/')[6])\n",
    "        # add auto name\n",
    "        auto_characteristics.append('model_name')\n",
    "        auto_characteristics.append(page.find('h1').text)\n",
    "        # add price\n",
    "        auto_characteristics.append('price')\n",
    "        price = page.find('span', class_='OfferPriceCaption__price').text\n",
    "        price = price.replace('\\xa0', '')\n",
    "        auto_characteristics.append(price)\n",
    "\n",
    "        # loop to find al'l other auto characteristics\n",
    "        for characteristics in page.find_all('span', class_='CardInfoRow__cell'):\n",
    "            auto_characteristics.append(characteristics.text)\n",
    "\n",
    "        # add seller comments\n",
    "        auto_characteristics.append('comment')\n",
    "        auto_characteristics.append(\n",
    "            page.find('div', class_='CardDescription__text').text)\n",
    "\n",
    "        auto_characteristics_dict = dict([(x, y) for x, y in zip(\n",
    "            auto_characteristics[::2], auto_characteristics[1::2])])\n",
    "        temp_df = pd.DataFrame([auto_characteristics_dict])\n",
    "        df = pd.concat([df, temp_df])\n",
    "    except:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
